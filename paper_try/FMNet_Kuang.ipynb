{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMNet  \n",
    "## Required packages\n",
    "`conda install numpy scipy tqdm plyfile trimesh joblib torchvision`  \n",
    "`conda install -c pytorch-lts pytorch`  \n",
    "`conda install -c conda-forge scikit-learn`  \n",
    "`conda install -c conda-forge networkx`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "# 3p\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils.graph import graph_shortest_path\n",
    "import trimesh\n",
    "import networkx as nx\n",
    "# project\n",
    "import utils.shot.shot as shot\n",
    "from utils.io import read_mesh\n",
    "from utils.laplace_decomposition import laplace_decomposition\n",
    "\n",
    "# SHOT's hyperparameters\n",
    "NORMAL_R = 0.1\n",
    "SHOT_R = 0.1\n",
    "KNN = 20\n",
    "\n",
    "\n",
    "def compute_geodesic_matrix(verts, faces, NN):\n",
    "    # get adjacency matrix\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=faces, process=False)\n",
    "    vertex_adjacency = mesh.vertex_adjacency_graph\n",
    "    vertex_adjacency_matrix = nx.adjacency_matrix(vertex_adjacency, range(verts.shape[0]))\n",
    "    # get adjacency distance matrix\n",
    "    graph_x_csr = neighbors.kneighbors_graph(verts, n_neighbors=NN, mode='distance', include_self=False)\n",
    "    distance_adj = csr_matrix((verts.shape[0], verts.shape[0])).tolil()\n",
    "    distance_adj[vertex_adjacency_matrix != 0] = graph_x_csr[vertex_adjacency_matrix != 0]\n",
    "    # compute geodesic matrix\n",
    "    geodesic_x = graph_shortest_path(distance_adj, directed=False)\n",
    "    return geodesic_x\n",
    "\n",
    "\n",
    "def process_mesh(mesh, corres_root, save_dir, args):\n",
    "    new_name = mesh.stem\n",
    "\n",
    "    verts, faces = read_mesh(mesh)\n",
    "    # center shape\n",
    "    verts -= np.mean(verts, axis=0)\n",
    "\n",
    "    # compute decomposition\n",
    "    evals, evecs, evecs_trans, old_sqrt_area = laplace_decomposition(verts, faces, args.num_eigen)\n",
    "\n",
    "    # normalize area and save\n",
    "    verts /= old_sqrt_area\n",
    "\n",
    "    # recompute decomposition and save eigenvalues\n",
    "    evals, evecs, evecs_trans, sqrt_area = laplace_decomposition(verts, faces, args.num_eigen)\n",
    "    print(f\"shape {mesh.stem} ==> old sqrt area: {old_sqrt_area :.8f} | new sqrt area: {sqrt_area :.8f}\")\n",
    "\n",
    "    to_save = {\"pos\": verts, \"faces\": faces,\n",
    "               \"evals\": evals, \"evecs\": evecs, \"evecs_trans\": evecs_trans}\n",
    "\n",
    "    # compute geodesic matrix\n",
    "    geodesic_x = compute_geodesic_matrix(verts, faces, args.nn)\n",
    "    to_save[\"geod_dist\"] = geodesic_x\n",
    "\n",
    "    # compute shot descriptors\n",
    "    shot_features = shot.compute(verts, NORMAL_R, SHOT_R).reshape(-1, 352)\n",
    "    to_save[\"feat\"] = shot_features\n",
    "\n",
    "    # add correspandance\n",
    "    if corres_root is not None:\n",
    "        to_save[\"vts\"] = np.loadtxt(corres_root / f\"{new_name}.vts\", dtype=np.int32)\n",
    "\n",
    "    # save\n",
    "    sio.savemat(save_dir / f\"{new_name}.mat\", to_save)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    save_root = Path(args.save_dir)\n",
    "    save_root.mkdir(parents=True, exist_ok=True)\n",
    "    meshes_root = Path(args.dataroot / \"shapes\")\n",
    "    corres_root = Path(args.dataroot / \"correspondences\") if Path(args.dataroot / \"correspondences\").is_dir() else None\n",
    "\n",
    "    meshes = list(meshes_root.iterdir())\n",
    "    _ = Parallel(n_jobs=args.njobs)(delayed(process_mesh)(mesh, corres_root, save_root, args)\n",
    "                                    for mesh in tqdm(meshes))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\"\"Preprocess data for FMNet training.\n",
    "                       Compute Laplacian eigen decomposition, shot features, and geodesic distance for each shape.\"\"\"\n",
    "    )\n",
    "    parser.add_argument('-d', '--dataroot', required=False,\n",
    "                        default=\"../data/faust/raw\", help='root directory of the dataset')\n",
    "    parser.add_argument('-sd', '--save-dir', required=False,\n",
    "                        default=\"../data/faust/processed\", help='root directory to save the processed dataset')\n",
    "    parser.add_argument(\"-ne\", \"--num-eigen\", type=int, default=100, help=\"number of eigenvectors kept.\")\n",
    "    parser.add_argument(\"-nj\", \"--njobs\", type=int, default=-2, help=\"Number of parallel processes to use.\")\n",
    "    parser.add_argument(\"--nn\", type=int, default=20,\n",
    "                        help=\"Number of Neighbor to consider when computing geodesic matrix.\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## faust_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import permutations\n",
    "# 3p\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class FAUSTDataset(Dataset):\n",
    "    \"\"\"FAUST dataset\"\"\"\n",
    "    def __init__(self, root, dim_basis=100, transform=None):\n",
    "        self.root = root\n",
    "        self.dim_basis = dim_basis\n",
    "        self.transform = transform\n",
    "        self.samples = [join(root, f) for f in listdir(root) if isfile(join(root, f))]\n",
    "        self.combinations = list(permutations(range(len(self.samples)), 2))\n",
    "\n",
    "    def loader(self, path):\n",
    "        \"\"\"\n",
    "        pos: num_vertices * 3\n",
    "        evecs: num_vertices * n_basis\n",
    "        evecs_trans: n_basis * num_vertices\n",
    "        feat: num_vertices * n_features\n",
    "        dist: num_vertices * num_vertices\n",
    "        \"\"\"\n",
    "        mat = sio.loadmat(path)\n",
    "        return (torch.Tensor(mat['feat']).float(), torch.Tensor(mat['evecs'])[:, :self.dim_basis].float(),\n",
    "                torch.Tensor(mat['evecs_trans'])[:self.dim_basis, :].float(),\n",
    "                torch.Tensor(mat['geod_dist']).float(), torch.Tensor(mat['vts']).long())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.combinations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx1, idx2 = self.combinations[index]\n",
    "        path1, path2 = self.samples[idx1], self.samples[idx2]\n",
    "\n",
    "        feat_x, evecs_x, evecs_trans_x, dist_x, vts_x = self.loader(path1)\n",
    "        feat_x, evecs_x, evecs_trans_x, dist_x = feat_x[vts_x], evecs_x[vts_x], evecs_trans_x[:, vts_x], dist_x[vts_x][:, vts_x]\n",
    "        feat_y, evecs_y, evecs_trans_y, dist_y, vts_y = self.loader(path2)\n",
    "        feat_y, evecs_y, evecs_trans_y, dist_y = feat_y[vts_y], evecs_y[vts_y], evecs_trans_y[:, vts_y], dist_y[vts_y][:, vts_y]\n",
    "        if self.transform is not None:\n",
    "            feat_x, evecs_x, evecs_trans_x, dist_x = self.transform((feat_x, evecs_x, evecs_trans_x, dist_x))\n",
    "            feat_y, evecs_y, evecs_trans_y, dist_y = self.transform((feat_y, evecs_y, evecs_trans_y, dist_y))\n",
    "\n",
    "        return [feat_x, evecs_x, evecs_trans_x, dist_x, feat_y, evecs_y, evecs_trans_y, dist_y]\n",
    "\n",
    "\n",
    "class RandomSampling(object):\n",
    "    def __init__(self, num_vertices):\n",
    "        self.num_vertices = num_vertices\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feat_x, evecs_x, evecs_trans_x, dist_x = sample\n",
    "        vertices = np.random.choice(feat_x.size(0), self.num_vertices)\n",
    "        feat_x = feat_x[vertices, :]\n",
    "        evecs_x = evecs_x[vertices, :]\n",
    "        evecs_trans_x = evecs_trans_x[:, vertices]\n",
    "        dist_x = dist_x[vertices, :][:, vertices]\n",
    "\n",
    "        return feat_x, evecs_x, evecs_trans_x, dist_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3p\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SoftErrorLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate soft error loss as defined is FMNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, P, geodesic_dist):\n",
    "        \"\"\"Compute soft error loss\n",
    "\n",
    "        Arguments:\n",
    "            P {torch.Tensor} -- soft correspondence matrix. Shape: batch_size x num_vertices x num_vertices.\n",
    "            geodesic_dist {torch.Tensor} -- geodesic distances on Y. Shape: batch_size x num_vertices x num_vertices.\n",
    "\n",
    "        Returns:\n",
    "            float -- total loss\n",
    "        \"\"\"\n",
    "        loss = torch.sqrt(((P * geodesic_dist) ** 2).sum((1, 2)))\n",
    "        return torch.mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3p\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Implement one residual block as presented in FMNet paper.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, out_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(out_dim, eps=1e-3, momentum=1e-3)\n",
    "        self.fc2 = nn.Linear(out_dim, out_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(out_dim, eps=1e-3, momentum=1e-3)\n",
    "\n",
    "        if in_dim != out_dim:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Linear(in_dim, out_dim),\n",
    "                # nn.BatchNorm1d(out_dim)  # non implemented in original FMNet paper, suggested in resnet paper\n",
    "            )\n",
    "        else:\n",
    "            self.projection = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_res = F.relu(self.bn1(self.fc1(x).transpose(1, 2)).transpose(1, 2))\n",
    "        x_res = self.bn2(self.fc2(x_res).transpose(1, 2)).transpose(1, 2)\n",
    "        if self.projection:\n",
    "            x = self.projection(x)\n",
    "        x_res += x\n",
    "        return F.relu(x_res)\n",
    "\n",
    "\n",
    "class RefineNet(nn.Module):\n",
    "    \"\"\"Implement the refine net of FMNet. Take as input hand-crafted descriptors.\n",
    "       Output learned descriptors well suited to the task of correspondence\"\"\"\n",
    "    def __init__(self, n_residual_blocks=7, in_dim=352):\n",
    "        super().__init__()\n",
    "        model = []\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_dim, in_dim)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"One pass in refine net.\n",
    "\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- input hand-crafted descriptor. Shape: batch-size x num-vertices x num-features\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor -- learned descriptor. Shape: batch-size x num-vertices x num-features\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class SoftcorNet(nn.Module):\n",
    "    \"\"\"Implement the net computing the soft correspondence matrix.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feat_x, feat_y, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y):\n",
    "        \"\"\"One pass in soft core net.\n",
    "\n",
    "        Arguments:\n",
    "            feat_x {Torch.Tensor} -- learned feature 1. Shape: batch-size x num-vertices x num-features\n",
    "            feat_y {Torch.Tensor} -- learned feature 2. Shape: batch-size x num-vertices x num-features\n",
    "            evecs_x {Torch.Tensor} -- eigen vectors decomposition of shape 1. Shape: batch-size x num-vertices x num-eigenvectors\n",
    "            evecs_y {Torch.Tensor} -- eigen vectors decomposition of shape 2. Shape: batch-size x num-vertices x num-eigenvectors\n",
    "            evecs_trans_x: {Torch.Tensor} -- inverse eigen vectors decomposition of shape 1. defined as evecs_x.t() @ mass_matrix.\n",
    "                                             Shape: batch-size x num-eigenvectors x num-vertices\n",
    "            evecs_trans_y: {Torch.Tensor} -- inverse eigen vectors decomposition of shape 2. defined as evecs_y.t() @ mass_matrix.\n",
    "                                             Shape: batch-size x num-eigenvectors x num-vertices\n",
    "\n",
    "        Returns:\n",
    "            Torch.Tensor -- soft correspondence matrix. Shape: batch_size x num_vertices x num_vertices.\n",
    "            Torch.Tensor -- Functional map matrix. Shape: batch_size x num-eigenvectors x num-eigenvectors.\n",
    "        \"\"\"\n",
    "        # compute linear operator matrix representation C\n",
    "        F_hat = torch.bmm(evecs_trans_x, feat_x)\n",
    "        G_hat = torch.bmm(evecs_trans_y, feat_y)\n",
    "        F_hat, G_hat = F_hat.transpose(1, 2), G_hat.transpose(1, 2)\n",
    "        Cs = []\n",
    "        for i in range(feat_x.size(0)):\n",
    "            C = torch.inverse(F_hat[i].t() @ F_hat[i]) @ F_hat[i].t() @ G_hat[i]\n",
    "            Cs.append(C.t().unsqueeze(0))\n",
    "        C = torch.cat(Cs, dim=0)\n",
    "\n",
    "        # compute soft correspondence matrix P\n",
    "        P = torch.abs(torch.bmm(torch.bmm(evecs_y, C), evecs_trans_x))\n",
    "        P = F.normalize(P, 2, dim=1)\n",
    "        return P, C\n",
    "\n",
    "\n",
    "class FMNet(nn.Module):\n",
    "    \"\"\"Implement the FMNet network as described in the paper.\"\"\"\n",
    "    def __init__(self, n_residual_blocks=7, in_dim=352):\n",
    "        \"\"\"Initialize network.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            n_residual_blocks {int} -- number of resnet blocks in FMNet (default: {7})\n",
    "            in_dim {int} -- Input features dimension (default SHOT descriptor) (default: {352})\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.refine_net = RefineNet(n_residual_blocks, in_dim)\n",
    "        self.softcor = SoftcorNet()\n",
    "\n",
    "    def forward(self, feat_x, feat_y, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y):\n",
    "        \"\"\"One pass in FMNet.\n",
    "\n",
    "        Arguments:\n",
    "            feat_x {Torch.Tensor} -- hand crafted feature 1. Shape: batch-size x num-vertices x num-features\n",
    "            feat_y {Torch.Tensor} -- hand crafted feature 2. Shape: batch-size x num-vertices x num-features\n",
    "            evecs_x {Torch.Tensor} -- eigen vectors decomposition of shape 1. Shape: batch-size x num-vertices x num-eigenvectors\n",
    "            evecs_y {Torch.Tensor} -- eigen vectors decomposition of shape 2. Shape: batch-size x num-vertices x num-eigenvectors\n",
    "\n",
    "        Returns:\n",
    "            Torch.Tensor -- soft correspondence matrix. Shape: batch_size x num_vertices x num_vertices.\n",
    "            Torch.Tensor -- matrix representation of functional correspondence.\n",
    "                            Shape: batch_size x num-eigenvectors x num-eigenvectors.\n",
    "        \"\"\"\n",
    "        feat_x = self.refine_net(feat_x)\n",
    "        feat_y = self.refine_net(feat_y)\n",
    "        P, C = self.softcor(feat_x, feat_y, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y)\n",
    "        return P, C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import argparse\n",
    "import os\n",
    "# 3p\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# project\n",
    "from model import FMNet\n",
    "from faust_dataset import FAUSTDataset, RandomSampling\n",
    "from loss import SoftErrorLoss\n",
    "\n",
    "\n",
    "def train_fmnet(args):\n",
    "    if torch.cuda.is_available() and not args.no_cuda:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "\n",
    "    # create dataset\n",
    "    print(\"creating dataset\")\n",
    "    composed = transforms.Compose([RandomSampling(args.n_vertices)])\n",
    "    dataset = FAUSTDataset(args.dataroot, args.dim_basis, transform=composed)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.n_cpu)\n",
    "    # create model\n",
    "    print(\"creating model\")\n",
    "    fmnet = FMNet(n_residual_blocks=args.num_blocks, in_dim=352).to(device)  # number of features of SHOT descriptor\n",
    "    optimizer = torch.optim.Adam(fmnet.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n",
    "    criterion = SoftErrorLoss().to(device)\n",
    "\n",
    "    # Training loop\n",
    "    print(\"start training\")\n",
    "    iterations = 0\n",
    "    for epoch in range(1, args.n_epochs + 1):\n",
    "        fmnet.train()\n",
    "        for i, data in enumerate(dataloader):\n",
    "            data = [x.to(device) for x in data]\n",
    "            feat_x, evecs_x, evecs_trans_x, dist_x, feat_y, evecs_y, evecs_trans_y, dist_y = data\n",
    "\n",
    "            # do iteration\n",
    "            P, _ = fmnet(feat_x, feat_y, evecs_x, evecs_y, evecs_trans_x, evecs_trans_y)\n",
    "            loss = criterion(P, dist_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # log\n",
    "            iterations += 1\n",
    "            if iterations % args.log_interval == 0:\n",
    "                print(f\"#epoch:{epoch}, #batch:{i + 1}, #iteration:{iterations}, loss:{loss}\")\n",
    "\n",
    "        # save model\n",
    "        if (epoch + 1) % args.checkpoint_interval == 0:\n",
    "            torch.save(fmnet.state_dict(), os.path.join(args.save_dir, 'epoch{}.pth'.format(epoch)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Launch the training of FMNet model.\"\n",
    "    )\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3, help=\"adam: learning rate\")\n",
    "    parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "    parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "    parser.add_argument(\"-bs\", \"--batch-size\", type=int, default=8, help=\"size of the batches\")\n",
    "    parser.add_argument(\"--n-epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "    parser.add_argument('--dim-basis', type=int, default=40,\n",
    "                        help='number of eigenvectors used for representation.')\n",
    "    parser.add_argument(\"-nv\", \"--n-vertices\", type=int, default=1500, help=\"Number of vertices used per shape\")\n",
    "    parser.add_argument(\"-nb\", \"--num-blocks\", type=int, default=7, help=\"number of resnet blocks\")\n",
    "    parser.add_argument('-d', '--dataroot', required=False, default=\"../data/faust/processed\",\n",
    "                        help='root directory of the dataset')\n",
    "    parser.add_argument('--save-dir', required=False, default=\"../data/save/\", help='root directory of the dataset')\n",
    "    parser.add_argument(\"--n-cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "    parser.add_argument('--no-cuda', action='store_true', help='Disable GPU computation')\n",
    "    parser.add_argument(\"--checkpoint-interval\", type=int, default=5, help=\"interval between model checkpoints\")\n",
    "    parser.add_argument(\"--log-interval\", type=int, default=1, help=\"interval between logging train information\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    train_fmnet(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fmnet_pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f9402ae41fa9e5b777600d2abfd30c5ec703e409414116ffbd42085910694a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
